{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjWsCAwv7na-"
      },
      "source": [
        "# PRA 2: Deep Learning para el análisis de textos\n",
        "\n",
        "En esta práctica revisaremos y aplicaremos los conocimientos aprendidos durante los últimos módulos del curso. En concreto trataremos los siguientes temas:\n",
        "\n",
        "1. **Traducción automática(TA)**: con custom embeddings y con embeddings preentrenados.\n",
        "2. **NER y NEL**: Entrenamiento de modelos de detección de entidades nombradas (NER), uso y clasificación.  Detección de entidades nombradas basándonos en Wikidata aplicada a NER.\n",
        "\n",
        "También incluimos algunos otros temas transversales trabajados a lo largo de la asignatura.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wknR5cFPUe9P"
      },
      "source": [
        "#0. Conexión con drive\n",
        "\n",
        "La ejecución de esta sección es opcional, pero muy recomendable si se trabaja en Colab.\n",
        "\n",
        "\n",
        "Aquí se realiza la conexión con drive y se establece el directorio de trabajo *actual*, en el que se almacenarán todos los recursos necesarios para ejecutar el notebook.\n",
        "\n",
        "\n",
        "\n",
        "El path de trabajo se debería colocar en la variable `my_path_pra2` y se sugiere crear una estructura de directorios como la siguiente.\n",
        "\n",
        "**Estructura de directorios**\n",
        "\n",
        "Establecer el directorio raiz según la variable `my_path_pra2`. En este directorio se almacenarán los datasets y directorios necesarios para la ejecución del notebook. La estructura y contenidos son los siguientes:\n",
        "\n",
        "    * directorio `TA` donde se almacenan los datos y recursos para realizar la traducción automática; contiene:\n",
        "      * glove.42B.300d.txt    # cargado por el usuario\n",
        "      * nld.txt      # cargado por el usuario\n",
        "      * directorio `model` donde se almacenan los *best model* del entrenamiento de los modelos de traducción automática:\n",
        "        * model_ta_en_de-g.keras    # 'best model' generado por el entrenamiento de TA con embeddings preentrenados\n",
        "        * model_ta_en_de.keras      # 'bestmodel' generado por el entrenamiento de TA con embeddings preentrenados\n",
        "    * directorio `NER` con los archivos necesarios para la práctica NER:\n",
        "        * Directorio `output_ner`   donde se almacena el *model-best* y *model-last* entrenados por este notebook\n",
        "        * config.cfg    # cargado por el usuario\n",
        "        * test.txt      # cargado por el usuario\n",
        "        * test.spacy    # Conversión de test.txt al formato spacy\n",
        "        * train.txt     # cargado por el usuario\n",
        "        * train.spacy   # Conversión de train.txt al formato spacy\n",
        "        * valid.txt     # cargado por el usuario\n",
        "        * valid.spacy   # Conversión de valid.txt al formato spacy\n",
        "\n",
        "\n",
        "\n",
        "**Ejecución de notebook en un entorn no `Colab`.**\n",
        "\n",
        "Si no se va a ejecutar este notebook en Colab, substituir esta sección (*0. Conexión on Drive*) por la correspondiente a la configuración deseada, teniendo en cuenta disponer de GPU con al menos 15 GB de memoria RAM.\n",
        "\n",
        "**Ejecucón de notebok en un entorno `Colab`.**\n",
        "\n",
        "Si se ejectua este notebook en Colab, debe utilizarse con al menos una GPU del tipo 'T4 GPU' o superior. Tener en cuenta que si se utiliza el servicio gratuito de Colab, estas GPU no están disponibles permanentemente y, cuando están disponibles, lo están solo mientras duran las 'compute units' asignadas al usuario o por límites de disponibilidad de GPUs de Google. Cuando éstas se agotan o no hay disponibilidad, debe esperarse a una nueva asignación. Google no publica el método de asignación o los [plazos de disposición](https://research.google.com/colaboratory/faq.html#usage-limits) de GPUs. La estructura de los directorios de trabajo debe ser la misma que la mencionada en el apartado anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPDd3zbYVPz4",
        "outputId": "cab0c7cf-0730-4499-e16a-b4b6c19e36b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Acceder a Colab myDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3QszncVUzq",
        "outputId": "df9c5b70-92de-4690-ec90-b2cad58d592a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root directory: '/content/drive/MyDrive'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Update path as needed; maintain the structure described.\n",
        "\n",
        "my_path_pra2 = \"/content/drive/MyDrive/\"\n",
        "\n",
        "if os.path.exists(my_path_pra2):\n",
        "    try:\n",
        "        os.chdir(my_path_pra2)\n",
        "        print(f\"Root directory: '{os.getcwd()}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error  changing directory: '{my_path_pra2}'. Error: {e}\")\n",
        "else:\n",
        "    print(f\"Directory '{my_path_pra2}' doesn't exist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlb9ckK-h6Te"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3mpBgbZh-Qv"
      },
      "outputs": [],
      "source": [
        "#############################################\n",
        "# SOLUCIÓ                                   #\n",
        "#############################################\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.utils import pad_sequences\n",
        "from keras import layers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "\n",
        "# ... Other imports ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyW13h9Z7nbB"
      },
      "source": [
        "# 1. Traducción Automática (TA) (7 puntos)\n",
        "\n",
        "\n",
        "En esta primera parte de la práctica se pide resolver los ejercicios usando la libreria **KERAS**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuKkXmmS7nbD"
      },
      "source": [
        "## 1.1 TA con Custom Embeddings (4,5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuhhJrUk7nbD"
      },
      "source": [
        "\n",
        "El objetivo de este apartado es entrenar un modelo de traducción automática de dos idiomas escogidos a partir del dataset elegido, siguiendo los mismos pasos que en el notebook de *Machine Translation* y el ejemplo proporcionado para el desarrollo de esta práctica `Ejemplo_PRA2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdz0sUSb7nbD"
      },
      "source": [
        "<strong>Implementación:</strong> Siguiendo los pasos trabajados en el notebook de traducción automática, implementar y entrenar un modelo de traducción automática, del **idioma origen** a **idioma destino**. Para ello, considerar los siguientes aspectos: <br>\n",
        "    - Decidir que dimensión que se usará en la capa embedding. Se sugiere empezar con 200 y luego se pedirá variar este valor para comparar los resultados.<br>\n",
        "    - Plantear una longitud de secuencia que tenga sentido. Inicialmente, se pedirá trabajar con 8, y su valor se ajustará según la carga de procesamiento.<br>\n",
        "    - Mostrar la aplicación del modelo entrenado (predicción) con datos del dataset de test.<br>\n",
        " <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFrf4gUrIJcK"
      },
      "source": [
        "### 1.1.0 Hiperparàmetres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOhBgbvJw9N"
      },
      "source": [
        "Notar que:\n",
        "\n",
        "* En este ejercicio utilitzaremos  'max_text_length' tanto para la secuencia de entrada como para la de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7dMBFz9IOAB"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "\n",
        "max_text_length = 8        # Maximum number of tokens allowed per input  and output sequence\n",
        "embedding_vec_length = 200     # Dimensionality of the dense vector representing each token.\n",
        "units = 512                    # LSTM Layer Units\n",
        "epochs = 50                    # Training epochs\n",
        "patience = 5                 # early stopping patience\n",
        "batch_size = 64               # Number of training examples per step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b3mC0ATqcAo"
      },
      "source": [
        "### 1.1.1 Preparación de datos (1 punto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L28axKt4kIwO"
      },
      "source": [
        "Primero preparamos los datos que se han elegido (tened en cuenta que el idioma origen debe ser **inglés**), de tal manera que, se puedan leer correctamente y estén preparados para tenerlos en un formato adecuado para la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0tpNpySqcAp"
      },
      "source": [
        "**a. Cargamos los datos desde la fuente seleccionada.**\n",
        "\n",
        "*Salidas esperadas:*\n",
        "- Longitud del dataset.\n",
        "- Al menos 3 filas de datos en las que se muestre textos del idioma origen y la respectiva traducción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVYldy9c7nbG",
        "outputId": "a20a25da-1d9b-4380-e17c-8f48aaa57b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del dataset: 412885 pares de frases.\n",
            "\n",
            "Muestra de las 3 primeras filas (Origen -> Destino):\n",
            "1. EN: Thank you so much, Chris.\n",
            "   ES: Muchas gracias Chris.\n",
            "2. EN: And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
            "   ES: Y es en verdad un gran honor tener la oportunidad de venir a este escenario por segunda vez. Estoy extremadamente agradecido.\n",
            "3. EN: I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
            "   ES: He quedado conmovido por esta conferencia, y deseo agradecer a todos ustedes sus amables comentarios acerca de lo que tenía que decir la otra noche.\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "ruta_en = \"/content/drive/MyDrive/TED2020.en-es.en\"\n",
        "ruta_es = \"/content/drive/MyDrive/TED2020.en-es.es\"\n",
        "\n",
        "# función de carga\n",
        "def load_data(path_en, path_es):\n",
        "    with open(path_en, 'r', encoding='utf-8') as f:\n",
        "        en_lines = f.read().split('\\n')\n",
        "    with open(path_es, 'r', encoding='utf-8') as f:\n",
        "        es_lines = f.read().split('\\n')\n",
        "    return en_lines, es_lines\n",
        "\n",
        "# Cargar y procesar\n",
        "raw_en, raw_es = load_data(ruta_en, ruta_es)\n",
        "\n",
        "# Emparejamos los datos y limpiamos líneas vacías\n",
        "data = []\n",
        "for en, es in zip(raw_en, raw_es):\n",
        "    if en.strip() and es.strip():\n",
        "        data.append([en.strip(), es.strip()])\n",
        "\n",
        "# resultados\n",
        "print(f\"Longitud del dataset: {len(data)} pares de frases.\")\n",
        "print(\"\\nMuestra de las 3 primeras filas (Origen -> Destino):\")\n",
        "for i in range(min(3, len(data))):\n",
        "    print(f\"{i+1}. EN: {data[i][0]}\")\n",
        "    print(f\"   ES: {data[i][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmFddVqkYU_"
      },
      "source": [
        "**b. Preprocesar los datos, para eliminar puntuaciones y poner en minúscula.**\n",
        "\n",
        "*Salida esperada:* Deberás mostrar un conjunto de datos limpio y normalizado. Por ejemplo, si la frase en el idioma origen, \"Hello, world!\" se transformará en \"hello world\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgIsoQqS7nbH",
        "outputId": "8d96451f-6400-42f7-ebba-f5680fc35f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muestra de datos limpios y normalizados:\n",
            "1. EN: thank you so much chris\n",
            "   ES: muchas gracias chris\n",
            "2. EN: and its truly a great honor to have the opportunity to come to this stage twice im extremely grateful\n",
            "   ES: y es en verdad un gran honor tener la oportunidad de venir a este escenario por segunda vez estoy extremadamente agradecido\n",
            "3. EN: i have been blown away by this conference and i want to thank all of you for the many nice comments about what i had to say the other night\n",
            "   ES: he quedado conmovido por esta conferencia y deseo agradecer a todos ustedes sus amables comentarios acerca de lo que tenía que decir la otra noche\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    # Pasamos a minúsculas\n",
        "    text = text.lower()\n",
        "    #  patrón para eliminar puntuación\n",
        "    # Reemplazar signos de puntuación por un espacio vacío\n",
        "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "    text = re_punc.sub('', text)\n",
        "    # Eliminar espacios en blanco extra\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "# limpieza a todo el dataset\n",
        "cleaned_data = []\n",
        "for pair in data:\n",
        "    cleaned_data.append([clean_text(pair[0]), clean_text(pair[1])])\n",
        "\n",
        "# Actualizamos  variable 'data' con los datos limpios\n",
        "data = cleaned_data\n",
        "\n",
        "# Resultados\n",
        "print(\"Muestra de datos limpios y normalizados:\")\n",
        "for i in range(3):\n",
        "    print(f\"{i+1}. EN: {data[i][0]}\")\n",
        "    print(f\"   ES: {data[i][1]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRInE02Skhbv"
      },
      "source": [
        "**c. Para tener una idea del tamaño de los textos a analizar, en función de la cantidad de palabras, visualizar los datos resultantes mediante un histograma.**\n",
        "\n",
        "*Salida esperada:* Dos histogramas que reflejen la cantidad de tokens de los textos del corpus, uno para los vectores del idioma origen y otro con los del destino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "d8LfflHB7nbI",
        "outputId": "8313c8d2-ff3b-4b7e-a697-3d468b98308f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "# Plot Source language\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculamos la longitud (número de palabras) de cada frase en inglés\n",
        "en_lengths = [len(pair[0].split()) for pair in data]\n",
        "\n",
        "# Graficamos\n",
        "plt.hist(en_lengths, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribución de longitudes - Inglés (Origen)')\n",
        "plt.xlabel('Número de palabras')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.savefig('hist_en.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "QyM_eI7U7nbI",
        "outputId": "64e21f61-3f6e-42b0-9398-a7a821799977"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "# Plot Target language\n",
        "# Calculamos la longitud de cada frase en español\n",
        "es_lengths = [len(pair[1].split()) for pair in data]\n",
        "\n",
        "# Graficamos\n",
        "plt.hist(es_lengths, bins=50, color='salmon', edgecolor='black')\n",
        "plt.title('Distribución de longitudes - Español (Destino)')\n",
        "plt.xlabel('Número de palabras')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.savefig('hist_es.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqDyZiEks-S"
      },
      "source": [
        "**d. Calcular el vocabulario tanto en el idioma origen , como en el idioma destino, e imprimir su tamaño**.\n",
        "\n",
        "*Resultado esperado:*\n",
        "* Se visualizarán dos números. Cada número representa el tamaño del vocabulario de las frases del idioma origen y del destino, respectivamente, después de haber aplicado el preprocesamiento y tokenización.\n",
        "* Lista de los 10 primeros tokens de cada idioma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTCjxsZMgj9E",
        "outputId": "ecd082fb-f767-4940-ea37-5ea5d5eacd7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario en Inglés (Origen): 84070 palabras únicas.\n",
            "Tamaño del vocabulario en Español (Destino): 120033 palabras únicas.\n",
            "\n",
            "Muestra de los 10 primeros tokens en Inglés:\n",
            "['unlocking', 'intermesh', 'furstenberg', 'powering', 'anticommunist', 'virologists', 'chriss', 'recurrent', 'juansharks', 'intensely']\n",
            "\n",
            "Muestra de los 10 primeros tokens en Español:\n",
            "['rocknroll', 'genéricas', 'metodista', 'escarcha', 'onu', 'furstenberg', 'preferirán', 'otorgado', 'cerillas', 'juansharks']\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "#  set para identificar palabras únicas de forma eficiente\n",
        "vocab_en = set()\n",
        "for pair in data:\n",
        "    for word in pair[0].split():\n",
        "        vocab_en.add(word)\n",
        "\n",
        "vocab_es = set()\n",
        "for pair in data:\n",
        "    for word in pair[1].split():\n",
        "        vocab_es.add(word)\n",
        "\n",
        "#  resultados de tamaño\n",
        "print(f\"Tamaño del vocabulario en Inglés (Origen): {len(vocab_en)} palabras únicas.\")\n",
        "print(f\"Tamaño del vocabulario en Español (Destino): {len(vocab_es)} palabras únicas.\")\n",
        "\n",
        "# muestra de los 10 primeros tokens encontrados\n",
        "# Nota: Los sets no tienen orden, así que la muestra será aleatoria\n",
        "print(\"\\nMuestra de los 10 primeros tokens en Inglés:\")\n",
        "print(list(vocab_en)[:10])\n",
        "\n",
        "print(\"\\nMuestra de los 10 primeros tokens en Español:\")\n",
        "print(list(vocab_es)[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPXEAlbGoSuL"
      },
      "source": [
        "**e. Separamos los conjuntos de entrenamiento por idioma y los codificamos.**\n",
        "\n",
        "En este paso, se separarán los datos en dos conjuntos: uno para entrenamiento (llamado *train*) y otro para prueba (llamado *test*), utilizando una división del 80% para entrenamiento y 20% para prueba.\n",
        "\n",
        "\n",
        "*Salida esperada:* tres primeras filas del dataset de entrenamiento *train*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX7rtG4Q7nbM",
        "outputId": "4e4c4b70-ada1-4149-e650-37c05f2c942a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del dataset de entrenamiento (train): 330308\n",
            "Tamaño del dataset de prueba (test): 82577\n",
            "\n",
            "Muestra de las 3 primeras filas del dataset de entrenamiento (train):\n",
            "1. EN: so lets do a little experiment together\n",
            "   ES: así que hagamos un pequeño experimento juntos\n",
            "2. EN: industry will not agree to increased regulation unless it believes this will stave off even more regulation or perhaps knock some competitors out of the market\n",
            "   ES: la industria no acordará incrementar las regulaciones a no ser que piense que esto evitará aún más regulaciones o que tal vez elimine algunos competidores del mercado\n",
            "3. EN: you can do things that you cannot see with your eyes\n",
            "   ES: pueden hacer cosas que no pueden ver con sus ojos\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#  train (80%) y test (20%)\n",
        "#  random_state para que la división sea siempre la misma\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Tamaño del dataset de entrenamiento (train): {len(train)}\")\n",
        "print(f\"Tamaño del dataset de prueba (test): {len(test)}\")\n",
        "\n",
        "print(\"\\nMuestra de las 3 primeras filas del dataset de entrenamiento (train):\")\n",
        "for i in range(3):\n",
        "    print(f\"{i+1}. EN: {train[i][0]}\")\n",
        "    print(f\"   ES: {train[i][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJbNLhqUc2ER"
      },
      "source": [
        "**f. Definir y aplicar una función para codificar las secuencias**\n",
        "\n",
        "En este paso, los dos conjuntos de datos creados en el punto anterior,  serán codificados usando **tokenización** y un proceso de **padding** para asegurar que todas las secuencias, de un mismo idioma, tienen la misma longitud.\n",
        "\n",
        "**Importante:** Para llevar a cabo un primer experimento, *dependiendo de la capacidad de procesamiento disponible para cada uno*, se sugiere ajustar el valor del parámetro **longitud de secuencia**, *hasta encontrar el valor más alto posible que, permita entrenar el modelo encoder-decoder, en un tiempo aceptable.*\n",
        "\n",
        "El parámetro **longitud de secuencia** tiene un impacto importante en el entrenamiento del modelo. Un valor alto permite al modelo capturar más contexto en las frases, lo cual es crucial para traducir correctamente oraciones complejas; sin embargo, si la longitud es demasiado corta, el modelo puede truncar frases importantes, perdiendo información clave. Uso de memoria y eficiencia computacional:\n",
        "\n",
        "Además, longitudes mayores requieren más memoria, ya que el modelo debe manejar matrices más grandes para representar las secuencias. Mientras que, longitudes cortas son más eficientes en términos de recursos, pero pueden sacrificar precisión si las oraciones reales exceden ese límite con frecuencia.\n",
        "\n",
        "Finalmente, en traducción automática, las longitudes de las secuencias en el idioma origen y destino no siempre deben ser iguales (por ejemplo, una oración en inglés puede ser más corta que su equivalente en alemán).\n",
        "\n",
        "Considerando lo anterior, si se dispone de infraestructura con GPU, se sugiere iniciar con un valor máximo de 12 (o cercano) y mínimo de 4.\n",
        "\n",
        "Si durante el entrenamiento, se presentan problemas (por limitación de infraestructura), se podría volver a este paso para fijar el valor mínimo de 4 para la longitud de secuencia de ambos idiomas, aunque, los resultados de la traducción serían pobres.\n",
        "\n",
        "\n",
        "**Salida esperada:** Tamaño de cada dataset y muestra de las tres primeras secuencias codificadas del dataset de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNjdWyEdc2r4",
        "outputId": "89c06148-849c-4697-cef9-8bb3d584418d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño vocabulario Inglés (indices): 84071\n",
            "Tamaño vocabulario Español (indices): 120034\n",
            "Forma de trainX: (330308, 8)\n",
            "Forma de trainY: (330308, 8)\n",
            "\n",
            "Muestra de las 3 primeras secuencias codificadas (Inglés):\n",
            "[[  14  202   33    5  124  862  175    0]\n",
            " [ 533 5714   75 6661   55    4    1  671]\n",
            " [  92    6   10  583   67   21   57  556]]\n"
          ]
        }
      ],
      "source": [
        "##############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#  Función para crear y entrenar el tokenizador\n",
        "def create_tokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        "\n",
        "# Preparar los tokenizadores basándonos en todo el dataset para cubrir todo el vocabulario\n",
        "en_tokenizer = create_tokenizer([pair[0] for pair in data])\n",
        "es_tokenizer = create_tokenizer([pair[1] for pair in data])\n",
        "\n",
        "# Guardar los tamaños de los vocabularios (+1 para el token de padding '0')\n",
        "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "es_vocab_size = len(es_tokenizer.word_index) + 1\n",
        "\n",
        "#. Función para codificar las frases y aplicar el padding\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # Convertimos el texto a secuencias de números\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # Aplicamos el padding (post: rellena con ceros al final de la frase)\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# codificar los datos de entrenamiento\n",
        "trainX = encode_sequences(en_tokenizer, max_text_length, [pair[0] for pair in train])\n",
        "trainY = encode_sequences(es_tokenizer, max_text_length, [pair[1] for pair in train])\n",
        "\n",
        "# codificar los datos de prueba\n",
        "testX = encode_sequences(en_tokenizer, max_text_length, [pair[0] for pair in test])\n",
        "testY = encode_sequences(es_tokenizer, max_text_length, [pair[1] for pair in test])\n",
        "\n",
        "# Resultados\n",
        "print(f\"Tamaño vocabulario Inglés (indices): {en_vocab_size}\")\n",
        "print(f\"Tamaño vocabulario Español (indices): {es_vocab_size}\")\n",
        "print(f\"Forma de trainX: {trainX.shape}\")\n",
        "print(f\"Forma de trainY: {trainY.shape}\")\n",
        "\n",
        "print(\"\\nMuestra de las 3 primeras secuencias codificadas (Inglés):\")\n",
        "print(trainX[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M9ZQnwKqcAt"
      },
      "source": [
        "### 1.1.2 Definición del modelo encoder-decoder y entrenamiento (2 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fYxSWIwoYSB"
      },
      "source": [
        "**a. Definimos el modelo *encoder-decoder* basándonos en el notebook visto en la asignatura**, y lo instanciamos con una capa de embedding para las frases de la **lengua origen** y la dimensión de la última capa como el vocabulario de la **lengua destino**.\n",
        "\n",
        "**Importante:** Para la definición del modelo, considerar los siguientes parámetros y valores referenciales:\n",
        "\n",
        "* Como cantidad de **units** trabajar, inicialmente, con el valor de 512. El número de unidades o celdas de memoria en cada capa LSTM define la dimensionalidad del espacio interno en el que la LSTM procesa y representa la información a lo largo del tiempo; es decir, es el tamaño del vector de estado oculto *hidden state* y del estado de celda *cell state* que la LSTM mantiene para capturar patrones y dependencias en las secuencias de entrada.\n",
        "\n",
        "* A mayor número de units, aumenta la capacidad del modelo para modelar relaciones complejas y dependencias a largo plazo en el texto, lo cual es clave en traducción automática donde el contexto puede abarcar varias palabras o frases. Sin embargo, un valor alto incrementa el número de parámetros, por tanto, se requerirá más memoria y tiempo de cómputo; además, crece el riesgo de sobreajuste si los datos de entrenamiento no son suficientes.\n",
        "\n",
        "* Longitud de los vectores de embeddings *embedding_vec_length* establecer en 200; este es un valor referencial que podría ser ajustado según el tamaño del vocabulario, la complejidad del idioma y los recursos disponibles. Más adelante, en el *ejercicio 1.1.3* se pedirá jugar un poco con este valor.\n",
        "\n",
        "**Resultado esperado:** se habrá instanciado un modelo encoder-decoder. Este modelo está diseñado para procesar y traducir textos del **idioma origen** al **idioma destino** utilizando capas de embedding y LSTM.\n",
        "\n",
        "*Salida esperada*: Utilizar el método *mt_model.summary()* para visualizar la estructura y configuración del modelo, incluyendo el número de parámetros y la disposición de las capas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "bGLbPLtE7nbN",
        "outputId": "50e6fb9d-ae1a-4bfc-d53f-7a36923affe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, RepeatVector, TimeDistributed\n",
        "\n",
        "def define_model(en_vocab, es_vocab, en_timesteps, es_timesteps, n_units, embedding_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    # ENCODER\n",
        "    # La capa de Embedding convierte los índices numéricos en vectores densos\n",
        "    model.add(Embedding(en_vocab, embedding_dim, input_length=en_timesteps, mask_zero=True))\n",
        "    # La LSTM del encoder captura el \"significado\" de la frase origen\n",
        "    model.add(LSTM(n_units))\n",
        "\n",
        "    # El RepeatVector actúa como puente, repitiendo el vector de contexto del encoder\n",
        "    model.add(RepeatVector(es_timesteps))\n",
        "\n",
        "    #  DECODER\n",
        "    # La LSTM del decoder genera la secuencia en el idioma destino\n",
        "    model.add(LSTM(n_units, return_sequences=True))\n",
        "    # TimeDistributed aplica una capa densa a cada paso de tiempo de la secuencia\n",
        "    model.add(TimeDistributed(Dense(es_vocab, activation='softmax')))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instanciar el modelo con los valores de tu dataset\n",
        "# Usamos max_text_length para ambos timesteps según las instrucciones\n",
        "mt_model = define_model(en_vocab_size, es_vocab_size, max_text_length, max_text_length, units, embedding_vec_length)\n",
        "\n",
        "# Visualizamos estructura\n",
        "mt_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuufosmqoxcA"
      },
      "source": [
        "**b. Compilamos el modelo**\n",
        "\n",
        "**Resultado esperado:** el modelo estará compilado y listo para ser entrenado. Se tiene que utilizar el optimizador *RMSprop* con una tasa de aprendizaje de *0.001* y la función de pérdida *sparse_categorical_crossentropy*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNwpJh4D7nbO",
        "outputId": "d5d1fb23-9cf8-4883-f9d1-010d9566708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo compilado con éxito.\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Compilar con los parámetros solicitados\n",
        "mt_model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "print(\"Modelo compilado con éxito.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuVDwSApo0VT"
      },
      "source": [
        "**c. Entrenamos y guardamos el modelo.**\n",
        "\n",
        "**Importante:** El modelo puede tardar horas si se hace en CPU, y requerirá mucho menos si existen GPUs disponibles. Colab permite el uso de GPU en general, si no se hace un uso extensivo, y se va deshabilitando la opción y habilitando segun necesidades. Si se tiene activada siempre penaliza y la desactiva.\n",
        "\n",
        "* Por tanto, para probar si funciona, recomendamos lanzar el entrenamiento **solo con una época** y ver que funciona. Una vez tenemos claro que el flujo está funcionando, subimos el valor (por ejemplo, 50 o 100, dependiendo cómo evoluciona el modelo con cada *epoch*).\n",
        "\n",
        "* Si, durante el entrenamiento, Colab no puede cargar el modelo en memoria, recomendamos bajar el valor de **longitud de palabra** a 4 y el número de **units** a 128, de esta manera podríamos completar el proceso, aunque, seguramente, los resultados no serán buenos.\n",
        "\n",
        "* Revisar el `Notebook de Ejemplo`, en el que se proporcionan pautas y guías para llevar un mejor control de las ejecuciones cuando ocurren reinicios de sesión o saturación de memoria.\n",
        "\n",
        "*Resultado esperado*\n",
        "* Path de la carpeta donde se ubicará el *best-model*\n",
        "* Gràfica validation_loss/training_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1muJyWc7nbO",
        "outputId": "f375af8b-897d-4a89-91d7-6e5f91311e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4129/4129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.1163 - loss: 7.2207\n",
            "Epoch 1: val_loss improved from inf to 6.72855, saving model to /content/drive/MyDrive/TA/model/model_ta_en_es.keras\n",
            "\u001b[1m4129/4129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1146s\u001b[0m 275ms/step - accuracy: 0.1163 - loss: 7.2206 - val_accuracy: 0.1453 - val_loss: 6.7286\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "\n",
        "# Definimos la ruta para guardar el modelo\n",
        "# Asegúrate de que el directorio 'TA/model' exista en tu Drive\n",
        "path_model = \"/content/drive/MyDrive/TA/model/model_ta_en_es.keras\"\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(path_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento de prueba (1 sola época)\n",
        "# Usamos un subconjunto o valid_split para monitorear el progreso\n",
        "history = mt_model.fit(trainX, trainY,\n",
        "                      epochs=1, # Cambia a 50 o 100 después de esta prueba\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[checkpoint, early_stop],\n",
        "                      verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T--13pcuVKOG"
      },
      "source": [
        "### 1.1.3 Predecir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rnmfh3GpdJ0"
      },
      "source": [
        "**a. Generar predicciones.**\n",
        "\n",
        "Una vez entrenado el modelo, aplicar el método *predict()* al conjunto de test para obtener las prediciones.\n",
        "\n",
        "**Sugerencia:**\n",
        "\n",
        "- Revisar el `Notebook de Ejemplo`, en el que proporciona una pauta para trabajar con un subconjunto del dataset de test, en caso de tener limitaciones durante el procesamiento.\n",
        "\n",
        "*Resultado esperado*\n",
        "* shape de las raw predictions (raw_preds) i\n",
        "* shape predictions (preds)\n",
        "* print de las dos primeras predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX74wIEu7nbP",
        "outputId": "54170e98-261d-4b6b-f4ba-9914199b0dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step\n",
            "\n",
            "Shape de las raw predictions: (100, 8, 120034)\n",
            "Shape de las predictions: (100, 8)\n",
            "\n",
            "Índices de las dos primeras predicciones:\n",
            "Pred 1: [2 2 1 1 1 1 0 0]\n",
            "Pred 2: [4 1 1 1 1 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#  muestra del conjunto de test para no saturar la memoria\n",
        "testX_sample = testX[:100]\n",
        "\n",
        "#  predicciones (raw_preds)\n",
        "# Esto nos devolverá una probabilidad para cada palabra del vocabulario\n",
        "raw_preds = mt_model.predict(testX_sample, verbose=1)\n",
        "\n",
        "#  índice de la palabra con mayor probabilidad (preds)\n",
        "preds = np.argmax(raw_preds, axis=-1)\n",
        "\n",
        "# Resultados\n",
        "print(f\"\\nShape de las raw predictions: {raw_preds.shape}\")\n",
        "print(f\"Shape de las predictions: {preds.shape}\")\n",
        "\n",
        "print(\"\\nÍndices de las dos primeras predicciones:\")\n",
        "print(f\"Pred 1: {preds[0]}\")\n",
        "print(f\"Pred 2: {preds[1]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drwik5f5pllA"
      },
      "source": [
        "**b. Visualización de resultados.**\n",
        "\n",
        "Visualizamos los resultados de las predicciones con los valores esperados.\n",
        "\n",
        "**Resultado esperado:** predicciones traducidas de las primeras 10 entradas del conjunto de prueba. Estas predicciones serán mostradas junto a los textos esperados para comparar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BNLHUKaLe9P",
        "outputId": "e8b0c7b7-8bce-470f-fe9a-10b3c5a1ffbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FUENTE (EN)                                        | REAL (ES)                                          | PREDICCIÓN (ES)\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "and so one kind of information space that i take i | un espacio de donde tomo inspiración es mi escrito | que que de de de de\n",
            "meditweet is an intelligent twitter bot that helps | meditweet es un bot de twitter inteligente que ayu | la de de de de de de\n",
            "and that really gives them a handle on a world in  | y eso en realidad es les da un control en un mundo | que que que que que de la\n",
            "but i think were a lot closer to erring on the sid | pero creo que estamos mucho más de cerca de errar  | la de de de de de de\n",
            "you dont know this planet because most of its cove | no conocemos este planeta porque la mayor parte es | que de de de de de la\n",
            "the holocaust which has the dubious distinction of | ¿el holocausto que tiene la dudosa distinción de s | de de de de de de de mundo\n",
            "so its going to be modular its going to be buoyant | constará de módulos que serán flotantes y estarán  | que que de de de de de\n",
            "weve lived with them all our lives                 | vivimos con él toda la vida                        | que de de de de de\n",
            "so i was amazed                                    | estaba asombrada                                   | no es\n",
            "and i mean it all went quite well but it always fe | y todo fue bien pero siempre sentí que faltaba alg | no que que que que\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "#  mapear un índice a su palabra correspondiente\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "#  convertir la secuencia de índices en una frase\n",
        "def decode_sequence(prediction, tokenizer):\n",
        "    words = []\n",
        "    for i in prediction:\n",
        "        if i == 0: # Saltamos el padding\n",
        "            continue\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "#  primeros 10 resultados del subconjunto de test\n",
        "print(f\"{'FUENTE (EN)':<50} | {'REAL (ES)':<50} | {'PREDICCIÓN (ES)'}\")\n",
        "print(\"-\" * 140)\n",
        "\n",
        "for i in range(10):\n",
        "    source_text = test[i][0]\n",
        "    real_text = test[i][1]\n",
        "    predicted_text = decode_sequence(preds[i], es_tokenizer)\n",
        "\n",
        "    # Formatear  la salida para que sea legible\n",
        "    print(f\"{source_text[:50]:<50} | {real_text[:50]:<50} | {predicted_text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlScdExYLdqb"
      },
      "source": [
        "f. **Pregunta de análisis:** Según los resultados obtenidos en la predicción (valores reales vs. valores generados), ¿Por qué creéis que no son buenos, y como creéis que podrían obtenerse mejores resultados?\n",
        "\n",
        "**¿Por qué no son buenos?**\n",
        "Porque el modelo únicamente ha visto el conjunto de datos una vez (1 epoch), lo cual es claramente insuficiente para manejar un vocabulario de unas 120.000 palabras. Además, una longitud de secuencia de solo 8 palabras resulta demasiado corta para las frases de TED, provocando que el modelo pierda gran parte del contexto necesario para realizar una traducción adecuada.\n",
        "\n",
        "**¿Cómo mejorar?**\n",
        "Se podría mejorar entrenando el modelo durante más épocas, aumentando la longitud de las secuencias (por ejemplo, a 15 o 20 palabras si la memoria lo permite) y, sobre todo, utilizando embeddings preentrenados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQGw9X9Rqsag"
      },
      "source": [
        "**Respuesta a la pregunta**\n",
        "-\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqE2RI7dqcAw"
      },
      "source": [
        "### 1.1.4 Experimentación con diferentes resultados (1,5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KKCg5OtiF7w"
      },
      "source": [
        "\n",
        "En este apartado, podríamos analizar cómo afecta a la calidad de la traducción, la variación de distintos parámetros del modelo, como:\n",
        "* longitud de embeddings (*embedding_vec_length*),\n",
        "* longitud de secuencia (*max_text_length*),\n",
        "* número de units (*units*),\n",
        "* batch size,\n",
        "* epochs etc.\n",
        "\n",
        "Sin embargo, debido a que no siempre encontraremos GPUs libres, aquí vamos vamos a limitarnos a experimentar con los parámetros:\n",
        "* *embedding_vec_length* y\n",
        "* *max_text_length*.\n",
        "\n",
        "**Importante:** durante las ejecuciones, dependiendo del modelo y del consumo de memoria actual, la predicción se puede cancelar por agotar toda la memoria disponible. En caso de cancelación, recargar el modelo desde local (ver apartado 1.1.2.2 del `Notebook de Ejemplo`) y predecir solo para un subconjunto del fichero de test (aunque en este caso no serán válidas las magnitudes de medición de calidad del sistema).  \n",
        "\n",
        "\n",
        "Además, se sugiere que tras cada entrenamiento, se realice una copia del modelo entrenado y se almacene en local *'model/..'* para, en caso de cancelación, no tener que realizar de nuevo el correspondiente entrenamiento, asociando a la copia los parámetros con los que se entrenó.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT7AWfrvTFFo"
      },
      "source": [
        "**a. Experimentar con el valor de longitud de embedding** (*embedding_vec_length*)\n",
        "\n",
        "Analizar cómo un incremento/reducción en el tamaño de los vectores de embedding afecta el rendimiento de un modelo de traducción automática del **idioma origen** al **idioma destino**.\n",
        "\n",
        "**Resultado esperado:** Se imprimirá el resultado que muestre el rendimiento del modelo creado para diferentes tamaños de embedding (inicialmente, se sugirió trabajar con 200; ahora, se podría experimentar con valores como 50 y 300). Cada resultado constará del tamaño del embedding seguido de un *score*, que indique la efectividad del modelo calculado con *model.evaluate()*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_OIoFheEKfu",
        "outputId": "a91a264b-43c7-4c43-dfc6-7b96d7723d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Entrenando modelo con Embedding Size: 50 \n",
            "\u001b[1m5162/5162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1207s\u001b[0m 233ms/step - accuracy: 0.1174 - loss: 7.1711\n",
            "Resultado para Embedding 50: Loss = 6.7725, Accuracy = 0.1333\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "# Definir  tamaños a probar\n",
        "embedding_sizes = [50]\n",
        "\n",
        "for size in embedding_sizes:\n",
        "    print(f\"\\n Entrenando modelo con Embedding Size: {size} \")\n",
        "\n",
        "    # definir nuevo modelo con el tamaño 'size'\n",
        "    model_exp = define_model(en_vocab_size, es_vocab_size, max_text_length, max_text_length, units, size)\n",
        "\n",
        "    #  Compilar\n",
        "    model_exp.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    #Entrenar (1 época para comparar rápido)\n",
        "    model_exp.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    # Evaluar con el conjunto de test\n",
        "    score = model_exp.evaluate(testX, testY, verbose=0)\n",
        "\n",
        "    print(f\"Resultado para Embedding {size}: Loss = {score[0]:.4f}, Accuracy = {score[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdUrxdHXTIe5"
      },
      "source": [
        "**b. Ejercicio opcional: Experimentar con el valor longitud de secuencia** (*max_text_length*).\n",
        "\n",
        "Analizar cómo un incremento/reducción de la longitud de secuencia impacta a la calidad del modelo de traducción.\n",
        "\n",
        "**Resultado esperado:** Se imprimirá el resultado que muestre el rendimiento del modelo para una longitud de secuencia superior o inferior al establecido (por ejemplo, si se inicializó el modelo preliminar con el valor de 8, aquí se podría probar con 4 y 12). El resultado constará del valor de la longitud, y del score que indica la efectividad del modelo calculado con *model.evaluate()*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPgcB87FT-61",
        "outputId": "bfa9d437-6fc0-48e0-fd96-e06faa66af1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Experimentando con Longitud de Secuencia: 12 \n",
            "\u001b[1m5162/5162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1818s\u001b[0m 351ms/step - accuracy: 0.1928 - loss: 6.4810\n",
            "\n",
            "Resultado para Longitud 12: Loss = 6.3161, Accuracy = 0.1741\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "# longitud de secuencia mayor (12)\n",
        "new_max_length = 12\n",
        "\n",
        "print(f\"\\n Experimentando con Longitud de Secuencia: {new_max_length} \")\n",
        "\n",
        "#  Re-codificamar las secuencias con la nueva longitud (padding a 12)\n",
        "trainX_12 = encode_sequences(en_tokenizer, new_max_length, [pair[0] for pair in train])\n",
        "trainY_12 = encode_sequences(es_tokenizer, new_max_length, [pair[1] for pair in train])\n",
        "testX_12 = encode_sequences(en_tokenizer, new_max_length, [pair[0] for pair in test])\n",
        "testY_12 = encode_sequences(es_tokenizer, new_max_length, [pair[1] for pair in test])\n",
        "\n",
        "# Definir el modelo para esta nueva longitud (usando units=512 y embedding=200)\n",
        "model_len_exp = define_model(en_vocab_size, es_vocab_size, new_max_length, new_max_length, units, embedding_vec_length)\n",
        "\n",
        "# compilar\n",
        "model_len_exp.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# entrenar\n",
        "model_len_exp.fit(trainX_12, trainY_12, epochs=1, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluar\n",
        "score_len = model_len_exp.evaluate(testX_12, testY_12, verbose=0)\n",
        "\n",
        "print(f\"\\nResultado para Longitud {new_max_length}: Loss = {score_len[0]:.4f}, Accuracy = {score_len[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyb8LvH0rqrq"
      },
      "source": [
        "Según los resultados obtenidos en este ejercicio 1.1.3, discutir en el *documento de Análisis* las diferencias encontradas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re2z6jLm7nbP"
      },
      "source": [
        "## 1.2 TA con Embeddings preentrenados (2,5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zzbdDJq7nbP"
      },
      "source": [
        "En este apartado repetiremos el ejercicio anterior cargando a la capa de embedding los pesos d'un modelo GloVe entrenado para el inglés.\n",
        "\n",
        "Este apartado 1.2 puede ejecutarse en diferentes sesiones de trabajo y no depende de las secciones anteriores a excepción de:\n",
        "* Ejecutar el apartado *0. Conexión con Drive* (o las celdas que se hayan definido para otros entornos no Colab).\n",
        "* Ejecutar el apartado *Imports*\n",
        "* Ejecutar el partado *1.1.0 Hiperparámetros. **IMPORTANTE** El parámetro *embedding_vec_length* ha de coincidr con la dimensión del vector de GloVe (inicialmente 300)\n",
        "* Ejecutar las celda de preparación de datos (sección 1.1.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3MS7zPlqcAy"
      },
      "source": [
        "### 1.2.1 Carga de GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vncpo5D7nbP"
      },
      "source": [
        "**a. Empezamos cargando el modelo GloVe para el inglés.**\n",
        "\n",
        "Podéis usar 'glove.42B.300d.txt'.(https://www.kaggle.com/datasets/yutanakamura/glove42b300dtxt)\n",
        "\n",
        "**Salida esperada:** tamaño del objeto cargado, usar *len()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZQ3Ze7vdxDj",
        "outputId": "83d9863c-3f58-46ca-849f-6aee4482409c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando vectores desde: /content/drive/MyDrive/glove.42B.300d.txt...\n",
            "Carga finalizada. Se han cargado 1917494 palabras.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = {}\n",
        "RUTA_GLOVE = '/content/drive/MyDrive/glove.42B.300d.txt'\n",
        "\n",
        "print(f\"Cargando vectores desde: {RUTA_GLOVE}...\")\n",
        "\n",
        "try:\n",
        "    with open(RUTA_GLOVE, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            # vector de 300 dimensiones\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    print(f\"Carga finalizada. Se han cargado {len(embeddings_index)} palabras.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar GloVe: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCu6o3oubiAI"
      },
      "source": [
        "### 1.2.2 Definición del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kajSHKSH7nbR"
      },
      "source": [
        "**a. Construir la matriz de embeddings.**\n",
        "  \n",
        "A continuación, tenemos que construir la matriz de embeddings.\n",
        "\n",
        "Para no cargar todo el vocabulario del modelo, podemos filtrar solo aquellas entradas presentes en el vocabulario del tokenizador que usaremos.\n",
        "\n",
        "Además, debemos de incluir en la matriz de vectores correspondientes los índices de las entradas (palabras) que no encontremos en el modelo glove cargado. Estos vectores se suelen inicializar con 0s o con el resultado de una distribución N (0,1).\n",
        "\n",
        "**Salida esperada:**\n",
        "* Dimensión de la matriz de embeddings.\n",
        "* Número de palabras que constan en GloVe y las que no constan.\n",
        "* imprimir los 3 primeros elementos de la matriz de embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0-OCm4XqcA4",
        "outputId": "b5d13f8e-b5cc-4b13-ccdf-15f872e45bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de embeddings creada con forma: (84071, 300)\n",
            "Palabras encontradas en GloVe: 68500\n",
            "Palabras no encontradas (misses): 15570\n",
            "\n",
            "Muestra del primer embedding (índice 1): [-0.20838    -0.14932001 -0.017528   -0.028432   -0.060104  ]...\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "# La dimensión debe coincidir con el archivo GloVe (300)\n",
        "embedding_dim_glove = 300\n",
        "# la matriz vacía (llena de ceros)\n",
        "embedding_matrix = np.zeros((en_vocab_size, embedding_dim_glove))\n",
        "\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Llenar la matriz con los vectores de GloVe\n",
        "for word, i in en_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Palabras encontradas en GloVe\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        # Palabras no encontradas (se quedan en cero)\n",
        "        misses += 1\n",
        "\n",
        "print(f\"Matriz de embeddings creada con forma: {embedding_matrix.shape}\")\n",
        "print(f\"Palabras encontradas en GloVe: {hits}\")\n",
        "print(f\"Palabras no encontradas (misses): {misses}\")\n",
        "\n",
        "# primeros 5 valores del primer embedding no nulo (por ej, el índice 1)\n",
        "print(f\"\\nMuestra del primer embedding (índice 1): {embedding_matrix[1][:5]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMMsDFOy7nbR"
      },
      "source": [
        "**b. Inicializar la capa de embeddings.**\n",
        "\n",
        "Para inicializar una capa de embeddings con pesos predefinidos se utiliza el argumento `weights`. Además, como no queremos que se modifiquen los pesos, marcamos el argumento `trainable` como `False`.\n",
        "\n",
        "*Resultado esperado*:\n",
        "\n",
        "Dimensiones de la capa de Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLjfzHAq7nbR",
        "outputId": "a04bbb82-c998-4fca-b7b3-6f13ea56c54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Capa de embedding inicializada con éxito (Longitud: 12)\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "#  longitud de secuencia del 1.1.4.b\n",
        "new_max_length = 12\n",
        "\n",
        "# capa de embedding con los pesos de GloVe\n",
        "# weights=[embedding_matrix] carga vectores preentrenados\n",
        "# trainable=False asegura que los pesos no cambien durante el entrenamiento\n",
        "embedding_layer_glove = Embedding(\n",
        "    input_dim=en_vocab_size,\n",
        "    output_dim=embedding_dim_glove,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=new_max_length,\n",
        "    trainable=False,\n",
        "    mask_zero=True\n",
        ")\n",
        "\n",
        "print(f\"Capa de embedding inicializada con éxito (Longitud: {new_max_length})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TAaf6I77nbR"
      },
      "source": [
        "**c. Definición del nuevo modelo considerando los pesos del modelo preentrenado.**\n",
        "\n",
        " Implementa y entrena de nuevo un modelo de traducción automática del **idioma origen** al **idioma destino**, esta vez, cargando los pesos de la capa embedding a partir del modelo Glove preentrenado en inglés y disponible en `glove.42B.300d.txt`.\n",
        "\n",
        " *Solución esperada*: 'summary' de la definición del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "9hKTQCdp7nbS",
        "outputId": "fd67e2d9-bba0-4ef3-c64e-0efe8053ab6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,221,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_3              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m25,221,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_3 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_3              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,221,300</span> (96.21 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,221,300\u001b[0m (96.21 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,221,300</span> (96.21 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,221,300\u001b[0m (96.21 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "def build_model_with_glove(n_units, es_vocab, es_timesteps, embedding_layer):\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer) # Usamos la capa que acabamos de corregir\n",
        "    model.add(LSTM(n_units))\n",
        "    model.add(RepeatVector(es_timesteps))\n",
        "    model.add(LSTM(n_units, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(es_vocab, activation='softmax')))\n",
        "    return model\n",
        "\n",
        "# Instanciar el modelo\n",
        "mt_model_glove = build_model_with_glove(\n",
        "    units,\n",
        "    es_vocab_size,\n",
        "    new_max_length,\n",
        "    embedding_layer_glove\n",
        ")\n",
        "\n",
        "mt_model_glove.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mN0znSTYnuf"
      },
      "source": [
        "d. **Compilamos el modelo**\n",
        "\n",
        "*Solución esperada*: 'summary' de la definición del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KnGbHD7Y6qw",
        "outputId": "a72b811d-e5af-4bda-a13d-023bd0db18f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo con GloVe compilado con éxito.\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Compilamos el modelo diseñado para GloVe\n",
        "mt_model_glove.compile(\n",
        "    optimizer=RMSprop(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Modelo con GloVe compilado con éxito.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9y3M34Yfm5G"
      },
      "source": [
        "### 1.2.3 Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqyHV6m3rIUn"
      },
      "source": [
        "**Entrenar y guardar el modelo.**\n",
        "\n",
        "Aunque este entrenamiento es quizá un \"poco\" más liviano que el anterior, recomendamos el uso de GPU si es viable.\n",
        "\n",
        "**Sugerencias:**\n",
        "\n",
        "- Probar con diferentes valores en *batch_size*. En el notebook de ejemplo se trabajó bien con el valor de 128.\n",
        "\n",
        "- Observar cómo evoluciona el modelo conforme se ejecuta cada *epoch*; en caso de no observar mejoras, se puede bajar su valor. En el notebook de ejemplo, se bajó el valor a 50 porque a partir de la *epoch* 32 no se notaron diferencias.\n",
        "\n",
        "- Revisar el `Notebook de Ejemplo`, subsección 1.2.3.2, en el que proporcionan pautas y guías para llevar un mejor control de las ejecuciones cuando ocurren reinicios de sesión o saturación de memoria.\n",
        "\n",
        "*Resultado esperado*\n",
        "\n",
        "* Path donde se ubicará el 'best model'\n",
        "* Plot validation_loss / training_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l58sRZaY7nbS",
        "outputId": "ede8008a-17fe-4de4-910d-8b7d17100df9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2065/2065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.1818 - loss: 6.5835\n",
            "Epoch 1: val_loss improved from inf to 6.09350, saving model to /content/drive/MyDrive/TA/model/model_ta_en_es_glove.keras\n",
            "\u001b[1m2065/2065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1428s\u001b[0m 689ms/step - accuracy: 0.1818 - loss: 6.5834 - val_accuracy: 0.2020 - val_loss: 6.0935\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "new_max_length = 12\n",
        "trainX_12 = encode_sequences(en_tokenizer, new_max_length, [pair[0] for pair in train])\n",
        "trainY_12 = encode_sequences(es_tokenizer, new_max_length, [pair[1] for pair in train])\n",
        "testX_12 = encode_sequences(en_tokenizer, new_max_length, [pair[0] for pair in test])\n",
        "testY_12 = encode_sequences(es_tokenizer, new_max_length, [pair[1] for pair in test])\n",
        "\n",
        "#  carpeta 'model' en Drive\n",
        "path_model_glove = \"/content/drive/MyDrive/TA/model/model_ta_en_es_glove.keras\"\n",
        "\n",
        "#  Callbacks para el control del entrenamiento\n",
        "checkpoint_glove = ModelCheckpoint(\n",
        "    path_model_glove,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "early_stop_glove = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=patience,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "#  entrenamiento\n",
        "history_glove = mt_model_glove.fit(\n",
        "    trainX_12,\n",
        "    trainY_12,\n",
        "    epochs=1,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[checkpoint_glove, early_stop_glove],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW-2Cnuqrbsu"
      },
      "source": [
        "### 1.2.4 Generación de predicciones\n",
        "\n",
        "En este paso, aplicar el modelo para generar las predicciones utilizando el dataset de test.\n",
        "\n",
        "**Resultado esperado:**\n",
        "\n",
        "* Shape de las raw predictions (raw_preds) i\n",
        "* Shape predictions (preds)\n",
        "* Print de las dos primeras predicciones.\n",
        "* Visualizar tabla de resultados: frase en idioma origen, texto traducido real vs. texto traducido generado.\n",
        "\n",
        "**Sugerencia:** Si durante la ejecución, se cancela la predicción por agotar toda la memoria disponible, recargar el modelo desde local (ver apartado 1.2.3.2 del `Notebook de Ejemplo`) y predecir solo para un subconjunto del fichero de test (aunque en este caso no serán validas las magnitudes de medición de calidad del sistema).   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efztL7bg7nbT",
        "outputId": "bd607f5a-2f60-405b-bbee-e15765627399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step\n",
            "FUENTE (EN)                                        | REAL (ES)                                          | PREDICCIÓN (GLOVE)\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "and so one kind of information space that i take i | un espacio de donde tomo inspiración es mi escrito | y y y y que que que que que que que\n",
            "meditweet is an intelligent twitter bot that helps | meditweet es un bot de twitter inteligente que ayu | y y y y y y y y y y y y\n",
            "and that really gives them a handle on a world in  | y eso en realidad es les da un control en un mundo | y que que que que que que que que que\n",
            "but i think were a lot closer to erring on the sid | pero creo que estamos mucho más de cerca de errar  | y que que que que que y\n",
            "you dont know this planet because most of its cove | no conocemos este planeta porque la mayor parte es | en en en y y y en en en en en en\n",
            "the holocaust which has the dubious distinction of | ¿el holocausto que tiene la dudosa distinción de s | en en en y y y y y en en en en\n",
            "so its going to be modular its going to be buoyant | constará de módulos que serán flotantes y estarán  | y que que que que que que que en en\n",
            "weve lived with them all our lives                 | vivimos con él toda la vida                        | y en en en\n",
            "so i was amazed                                    | estaba asombrada                                   | y es\n",
            "and i mean it all went quite well but it always fe | y todo fue bien pero siempre sentí que faltaba alg | y y que que que que que\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "#  muestra (ej. las primeras 100 frases) del conjunto de test codificado\n",
        "testX_sample = testX_12[:100]\n",
        "\n",
        "#  Predecir\n",
        "raw_preds_glove = mt_model_glove.predict(testX_sample, verbose=1)\n",
        "\n",
        "#  índices de las palabras\n",
        "preds_glove = np.argmax(raw_preds_glove, axis=-1)\n",
        "\n",
        "# Funciones de decodificación (mismas de antes)\n",
        "def decode_sequence(prediction, tokenizer):\n",
        "    words = []\n",
        "    for i in prediction:\n",
        "        if i == 0: continue\n",
        "        word = next((w for w, idx in tokenizer.word_index.items() if idx == i), None)\n",
        "        if word is None: break\n",
        "        words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "#  resultados (primeras 10 frases)\n",
        "print(f\"{'FUENTE (EN)':<50} | {'REAL (ES)':<50} | {'PREDICCIÓN (GLOVE)'}\")\n",
        "print(\"-\" * 140)\n",
        "\n",
        "for i in range(10):\n",
        "    source_text = test[i][0]\n",
        "    real_text = test[i][1]\n",
        "    predicted_text = decode_sequence(preds_glove[i], es_tokenizer)\n",
        "\n",
        "    print(f\"{source_text[:50]:<50} | {real_text[:50]:<50} | {predicted_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpRSYwVIwqZ1"
      },
      "source": [
        "# 2. Detección de NER y NEL (3 puntos)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrSiacuMyJyM"
      },
      "source": [
        "En esta segunda parte, nos enfocaremos en la detección de entidades nombradas (NER).\n",
        "\n",
        "Además, haremos Named Entity Linking (NEL) para buscar entidades enlazadas a una base de conocimiento (KB), en este caso la Wikidata. Encontraremos los enlaces a Wikidata de ciertas entidades de un texto, utilizando la API de Wikidata.\n",
        "\n",
        "Este apartado puede ejecutarse aisladamente y no depende del apartado anterior, a excepción de ejecutar el apartado *0. Conexión con Drive* (o las celdas que se hayan definido para otros entornos no Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMfY2OzVqcA6"
      },
      "source": [
        "## 2.1 Detección de NER (2 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc5mcU77gWpe"
      },
      "source": [
        "En esta primera subsección, detectaremos entidades nombradas, utilizando tanto spaCy como transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIAzOTIEiH5I"
      },
      "source": [
        "\n",
        "### 2.1.1 Detección de entidades nombradas (NER) usando spaCy.\n",
        "\n",
        "Para detectar NER usaremos el modelo `en_core_web_sm` de spaCy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq9EI0r7GEqi"
      },
      "source": [
        "**a. Instalar librerías y modelo de lenguaje a usar.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j5WkL16iH5Q",
        "outputId": "ba4cf64a-ff5a-4979-bb54-d0cea9361437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND86mIOO1Q-R",
        "outputId": "cc4dc1bf-c3dd-4874-f2a0-76216202aab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B_XppDS-qzY"
      },
      "source": [
        "**Importante:**\n",
        "\n",
        "Si la descarga de *'en_core_web_sm'* se realiza desde Google Colab y tras la descarga, aparece el mensaje 'Restart to reload dependencies', entonces, ejecutar la opción de menú 'Runtime>>>Restart session'. A continuación volver a ejecutar la sección 0 de este notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttkg0CqW4Ym9"
      },
      "source": [
        "**b. Definir funciones para imprimir los resultados de la detección.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8Ot3tH3lO48"
      },
      "outputs": [],
      "source": [
        "def get_tokens_to_print(model, text):\n",
        "  \"\"\"Print tokens of the text and its relevant attributes.\n",
        "\n",
        "    Parameters:\n",
        "      model (spaCy model): spaCy model used for tokenization\n",
        "      text (str):  text to transform in a spaCy doc class.\n",
        "\n",
        "    Returns: ---\n",
        "  \"\"\"\n",
        "  doc = model(text)\n",
        "  print (f\"The text:\\n\\n{get_text_to_print(text)}\\n\\nwas converted in a spaCy object: {type(doc)}\\n\")\n",
        "  print (f\"Token-based analysis. Each token is a spaCy object: {type(doc[0])}\\n\")\n",
        "\n",
        "  # We obtain rows to print: headers and content\n",
        "  rows  = []\n",
        "  # head_align: List of tuples. Each tuple: heather and its alignment when printing\n",
        "  head_align  = [('Token', '<'), ('Lemma', '<'), ('Syntactic parent', '<'), ('#Tok', '>'), ('Chr_Start', '>'), ('Chr_End', '>'), ('POS', '<'),\n",
        "                 ('TAG', '<'), ('TAG meaning:', '<'), ('ENT', '<'), ('DEP', '<'), ('DEP meaning:', '<')]\n",
        "  head, align = list(zip(*head_align))\n",
        "  rows.append(head)                           # Header\n",
        "  rows.append(['='*len(i) for i in head])     # Underline headers\n",
        "  for tok in doc:\n",
        "    rows.append([tok.text, tok.lemma_, tok.head.text, str(tok.i), str(tok.idx), str(tok.idx+len(tok)-1), tok.pos_,\n",
        "                 tok.tag_, str(spacy.explain(tok.tag_))[:20], tok.ent_type_, tok.dep_, str(spacy.explain(tok.dep_))[:20]])\n",
        "\n",
        "  # Width of each column: the witdh of the longest element\n",
        "  columns       = zip(*rows)\n",
        "  column_widths = [max(len(i) for i in col) for col in columns]\n",
        "\n",
        "  # Print the files with alignment\n",
        "  for row in rows:\n",
        "    print(*[f\"{row[i]:{align[i]}{column_widths[i]}}  \" for i in range(0, len(row))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9N8mQA3s56Z"
      },
      "outputs": [],
      "source": [
        "def get_text_to_print(text):\n",
        "  \"\"\"Format given text.\n",
        "\n",
        "    Parameters:\n",
        "      text (str): text to print\n",
        "\n",
        "    Returns:\n",
        "      str: text formatted in 100 character lines with an initial line numbering the characters\n",
        "  \"\"\"\n",
        "  line_length = 100\n",
        "  line_poss   = \"     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\"\n",
        "  text        = text.replace(\"\\n\", \" \")     # In order to avoid that the \\n character produces a line change.\n",
        "  text        = text.replace(\"\\r\", \" \")     # In wikipedia texts we have detected the character '\\r' that, if interpreted, may induce some printing problems.\n",
        "  text_format = \"\\n\".join([ f\"{i//line_length:<5}{text[i:i+line_length]}\"  for i in range(0, len(text), line_length) ])\n",
        "  return line_poss + \"\\n\" + text_format + \"\\n\" + line_poss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2xbabYm4uIe"
      },
      "source": [
        "**c. Cargar el modelo `en_core_web_sm`**\n",
        "\n",
        "**Resultado esperada**: Código para la carga del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLtWJNWHqcA9",
        "outputId": "74317787-78f2-47d4-b0ec-3dcb165896ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo 'en_core_web_sm' cargado correctamente.\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Cargamos el modelo pequeño de inglés\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "print(\"Modelo 'en_core_web_sm' cargado correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GCpZoQd4oqD"
      },
      "source": [
        "**d. Convertir un texto en objecto `Doc` de spaCy.**\n",
        "\n",
        "Para realizar la detección de entidades nombradas, proponer un texto en inglés que mencione a entidades de diferente tipo.\n",
        "\n",
        "\n",
        "**Salida Esperada**: Visualizar los resultados de analizar el texto propuesto a nivel de cada POS.\n",
        "\n",
        "**Sugerencia:** Para la visualización se puede utilizar la función *get_tokens_to_print()*, previamente creada, o *displacy.render()* de spaCy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIDs4LbelUjj",
        "outputId": "efee3224-c260-4ca0-9607-fecba4ce18e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text:\n",
            "\n",
            "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
            "0     LeBron James scored 30 points for the Los Angeles Lakers last night in California. Lionel Messi mov\n",
            "1    ed to Inter Miami in 2023 and has attracted thousands of fans to Florida. FC Barcelona remains one o\n",
            "2    f the most successful football clubs in Spain. \n",
            "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
            "\n",
            "was converted in a spaCy object: <class 'spacy.tokens.doc.Doc'>\n",
            "\n",
            "Token-based analysis. Each token is a spaCy object: <class 'spacy.tokens.token.Token'>\n",
            "\n",
            "Token        Lemma        Syntactic parent   #Tok   Chr_Start   Chr_End   POS     TAG    TAG meaning:           ENT        DEP        DEP meaning:          \n",
            "=====        =====        ================   ====   =========   =======   ===     ===    ============           ===        ===        ============          \n",
            "\n",
            "            \n",
            "            LeBron                0           0         0   SPACE   _SP    whitespace                        dep        unclassified depende  \n",
            "LeBron       LeBron       James                 1           1         6   PROPN   NNP    noun, proper singula   PERSON     compound   compound              \n",
            "James        James        scored                2           8        12   PROPN   NNP    noun, proper singula   PERSON     nsubj      nominal subject       \n",
            "scored       score        scored                3          14        19   VERB    VBD    verb, past tense                  ROOT       root                  \n",
            "30           30           points                4          21        22   NUM     CD     cardinal number        CARDINAL   nummod     numeric modifier      \n",
            "points       point        scored                5          24        29   NOUN    NNS    noun, plural                      npadvmod   noun phrase as adver  \n",
            "for          for          scored                6          31        33   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "the          the          Lakers                7          35        37   DET     DT     determiner             ORG        det        determiner            \n",
            "Los          Los          Angeles               8          39        41   PROPN   NNP    noun, proper singula   ORG        compound   compound              \n",
            "Angeles      Angeles      Lakers                9          43        49   PROPN   NNP    noun, proper singula   ORG        compound   compound              \n",
            "Lakers       Lakers       for                  10          51        56   PROPN   NNPS   noun, proper plural    ORG        pobj       object of prepositio  \n",
            "last         last         night                11          58        61   ADJ     JJ     adjective (English),   TIME       amod       adjectival modifier   \n",
            "night        night        scored               12          63        67   NOUN    NN     noun, singular or ma   TIME       npadvmod   noun phrase as adver  \n",
            "in           in           scored               13          69        70   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "California   California   in                   14          72        81   PROPN   NNP    noun, proper singula   GPE        pobj       object of prepositio  \n",
            ".            .            scored               15          82        82   PUNCT   .      punctuation mark, se              punct      punctuation           \n",
            "\n",
            "            \n",
            "            .                    16          83        83   SPACE   _SP    whitespace                        dep        unclassified depende  \n",
            "Lionel       Lionel       Messi                17          84        89   PROPN   NNP    noun, proper singula   PERSON     compound   compound              \n",
            "Messi        Messi        moved                18          91        95   PROPN   NNP    noun, proper singula   PERSON     nsubj      nominal subject       \n",
            "moved        move         moved                19          97       101   VERB    VBD    verb, past tense                  ROOT       root                  \n",
            "to           to           moved                20         103       104   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "Inter        Inter        Miami                21         106       110   PROPN   NNP    noun, proper singula   ORG        compound   compound              \n",
            "Miami        Miami        to                   22         112       116   PROPN   NNP    noun, proper singula   ORG        pobj       object of prepositio  \n",
            "in           in           moved                23         118       119   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "2023         2023         in                   24         121       124   NUM     CD     cardinal number        DATE       pobj       object of prepositio  \n",
            "and          and          moved                25         126       128   CCONJ   CC     conjunction, coordin              cc         coordinating conjunc  \n",
            "has          have         attracted            26         130       132   AUX     VBZ    verb, 3rd person sin              aux        auxiliary             \n",
            "attracted    attract      moved                27         134       142   VERB    VBN    verb, past participl              conj       conjunct              \n",
            "thousands    thousand     attracted            28         144       152   NOUN    NNS    noun, plural           CARDINAL   dobj       direct object         \n",
            "of           of           thousands            29         154       155   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "fans         fan          of                   30         157       160   NOUN    NNS    noun, plural                      pobj       object of prepositio  \n",
            "to           to           attracted            31         162       163   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "Florida      Florida      to                   32         165       171   PROPN   NNP    noun, proper singula   GPE        pobj       object of prepositio  \n",
            ".            .            moved                33         172       172   PUNCT   .      punctuation mark, se              punct      punctuation           \n",
            "\n",
            "            \n",
            "            .                    34         173       173   SPACE   _SP    whitespace                        dep        unclassified depende  \n",
            "FC           FC           Barcelona            35         174       175   PROPN   NNP    noun, proper singula              compound   compound              \n",
            "Barcelona    Barcelona    remains              36         177       185   PROPN   NNP    noun, proper singula   GPE        nsubj      nominal subject       \n",
            "remains      remain       remains              37         187       193   VERB    VBZ    verb, 3rd person sin              ROOT       root                  \n",
            "one          one          remains              38         195       197   NUM     CD     cardinal number        CARDINAL   attr       attribute             \n",
            "of           of           one                  39         199       200   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "the          the          clubs                40         202       204   DET     DT     determiner                        det        determiner            \n",
            "most         most         successful           41         206       209   ADV     RBS    adverb, superlative               advmod     adverbial modifier    \n",
            "successful   successful   clubs                42         211       220   ADJ     JJ     adjective (English),              amod       adjectival modifier   \n",
            "football     football     clubs                43         222       229   NOUN    NN     noun, singular or ma              compound   compound              \n",
            "clubs        club         of                   44         231       235   NOUN    NNS    noun, plural                      pobj       object of prepositio  \n",
            "in           in           clubs                45         237       238   ADP     IN     conjunction, subordi              prep       prepositional modifi  \n",
            "Spain        Spain        in                   46         240       244   PROPN   NNP    noun, proper singula   GPE        pobj       object of prepositio  \n",
            ".            .            remains              47         245       245   PUNCT   .      punctuation mark, se              punct      punctuation           \n",
            "\n",
            "            \n",
            "            .                    48         246       246   SPACE   _SP    whitespace                        dep        unclassified depende  \n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "text_ner = \"\"\"\n",
        "LeBron James scored 30 points for the Los Angeles Lakers last night in California.\n",
        "Lionel Messi moved to Inter Miami in 2023 and has attracted thousands of fans to Florida.\n",
        "FC Barcelona remains one of the most successful football clubs in Spain.\n",
        "\"\"\"\n",
        "\n",
        "# Analizamos el texto y visualizamos los tokens con la función definida antes\n",
        "get_tokens_to_print(nlp, text_ner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHr-Nz6czi3P"
      },
      "source": [
        "### 2.1.2 Entrenar un nuevo modelo de NER con el corpus de detección de entidades escogido.\n",
        "\n",
        "**a. Convertir el corpus elegido al formato que entiende spaCy.**\n",
        "\n",
        "*Sugerencia:* Si el corpus es grande, y el entrenamiento está tardando demasiado, puedes generar una versión más reducida de todos los ficheros del corpus elegido (train, dev y test). La reducción estaría bien de hacerla del 25%.\n",
        "\n",
        "Recuerda que spaCy contiene funciones que permiten convertir formatos como *conll* al formato compilado que necesita el módulo de train de spaCy.\n",
        "\n",
        "**Salida esperada:** Código para convertir el corpus training (train.txt) y el de validacion (valid.txt), del formato origen a spaCy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSK2mC0prNKK",
        "outputId": "659ad5e2-c644-4277-975a-b22ff86ff824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-17 18:17:08--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3281528 (3.1M) [text/plain]\n",
            "Saving to: ‘/content/drive/MyDrive/NER/train.txt’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   3.13M  9.67MB/s    in 0.3s    \n",
            "\n",
            "2026-01-17 18:17:09 (9.67 MB/s) - ‘/content/drive/MyDrive/NER/train.txt’ saved [3281528/3281528]\n",
            "\n",
            "--2026-01-17 18:17:10--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testa\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 827012 (808K) [text/plain]\n",
            "Saving to: ‘/content/drive/MyDrive/NER/valid.txt’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>] 807.63K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2026-01-17 18:17:10 (6.06 MB/s) - ‘/content/drive/MyDrive/NER/valid.txt’ saved [827012/827012]\n",
            "\n",
            "--2026-01-17 18:17:11--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748096 (731K) [text/plain]\n",
            "Saving to: ‘/content/drive/MyDrive/NER/test.txt’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>] 730.56K  4.64MB/s    in 0.2s    \n",
            "\n",
            "2026-01-17 18:17:11 (4.64 MB/s) - ‘/content/drive/MyDrive/NER/test.txt’ saved [748096/748096]\n",
            "\n",
            "\n",
            " Archivos descargados en: /content/drive/MyDrive/NER/\n",
            "Contenido actual: ['config.cfg', 'output_ner', 'output', 'valid.txt', 'train.txt', 'train.spacy', 'test.txt', 'valid.spacy', 'test.spacy']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "ruta_ner = \"/content/drive/MyDrive/NER/\"\n",
        "\n",
        "if not os.path.exists(ruta_ner):\n",
        "    os.makedirs(ruta_ner)\n",
        "\n",
        "\n",
        "!wget -O {ruta_ner}train.txt https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train\n",
        "!wget -O {ruta_ner}valid.txt https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testa\n",
        "!wget -O {ruta_ner}test.txt https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testb\n",
        "\n",
        "print(f\"\\n Archivos descargados en: {ruta_ner}\")\n",
        "print(f\"Contenido actual: {os.listdir(ruta_ner)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYfj6_LVziVV",
        "outputId": "958689c7-0f7f-411d-e7ca-7915511a4884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explorando directorio: /content/drive/MyDrive/NER\n",
            "\n",
            " Archivos detectados en Drive: ['config.cfg', 'output_ner', 'output', 'valid.txt', 'train.txt', 'train.spacy', 'test.txt', 'valid.spacy', 'test.spacy']\n",
            "\n",
            " Convirtiendo: train.txt \n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n",
            "disabled.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (946 documents):\n",
            "/content/drive/MyDrive/NER/train.spacy\u001b[0m\n",
            " [OK] Conversión finalizada para train\n",
            "\n",
            " Convirtiendo: valid.txt \n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n",
            "disabled.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (216 documents):\n",
            "/content/drive/MyDrive/NER/valid.spacy\u001b[0m\n",
            " [OK] Conversión finalizada para valid\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "def convert_ner_corpus(path_ner, file_list):\n",
        "    \"\"\"Convierte archivos de texto (CoNLL/IOB) al formato binario .spacy.\n",
        "\n",
        "    Parameters:\n",
        "      path_ner (str): Ruta de la carpeta NER en Drive.\n",
        "      file_list (list): Lista con los nombres de los archivos a convertir (ej. ['train', 'valid']).\n",
        "\n",
        "    Returns: ---\n",
        "    \"\"\"\n",
        "    print(f\"Explorando directorio: {path_ner}\\n\")\n",
        "\n",
        "    #  Verificación de seguridad: ¿Existe la carpeta?\n",
        "    if not os.path.exists(path_ner):\n",
        "        try:\n",
        "            os.makedirs(path_ner)\n",
        "            print(f\" [INFO] Carpeta creada correctamente: {path_ner}\")\n",
        "        except OSError as e:\n",
        "            print(f\" [ERROR] No se pudo crear la carpeta: {e}\")\n",
        "            return\n",
        "\n",
        "    # Listado de archivos para diagnóstico\n",
        "    found_files = os.listdir(path_ner)\n",
        "    print(f\" Archivos detectados en Drive: {found_files}\")\n",
        "\n",
        "    #  Proceso de conversión\n",
        "    for file_name in file_list:\n",
        "        full_input_path = os.path.join(path_ner, f\"{file_name}.txt\")\n",
        "\n",
        "        if f\"{file_name}.txt\" in found_files:\n",
        "            print(f\"\\n Convirtiendo: {file_name}.txt \")\n",
        "            try:\n",
        "                # Ejecutamos el comando de spaCy para convertir el formato\n",
        "                !python -m spacy convert {full_input_path} {path_ner} --converter ner\n",
        "                print(f\" [OK] Conversión finalizada para {file_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\" [ERROR] Falló la conversión de {file_name}: {e}\")\n",
        "        else:\n",
        "            print(f\"\\n [ADVERTENCIA] El archivo '{file_name}.txt' NO está en la carpeta.\")\n",
        "            print(f\"  Sube '{file_name}.txt'  a {path_ner}\")\n",
        "\n",
        "# Definimos la ruta y los archivos según tu configuración\n",
        "RUTA_NER = \"/content/drive/MyDrive/NER\"\n",
        "ARCHIVOS_A_PROCESAR = [\"train\", \"valid\"]\n",
        "\n",
        "# Ejecutamos la función de conversión\n",
        "convert_ner_corpus(RUTA_NER, ARCHIVOS_A_PROCESAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPjyFwFqcA9"
      },
      "source": [
        "**b. Descargar el modelo `en_core_web_trf`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guBDOqACqcA-",
        "outputId": "84f2792b-80e8-484b-a05b-e9114a259ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-trf==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
            "  Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
            "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_tokenizers-0.0.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.12/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.3)\n",
            "Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.9/237.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (734 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.0/734.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
            "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_trf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pohZJx077X9W"
      },
      "source": [
        "**Importante:** En Google Colab, si tras la descarga del modelo `en_core_web_trf` aparece el mensaje 'Restart to reload dependencies', deberá ejecutarse la opción de menú 'Runtime>>>Restart session'. Luego, para mayor seguridad, volver a ejecutar la sección 0 de este notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY804IZcM-ga",
        "outputId": "e1b72b57-6612-41e9-9de5-1ca6c621257d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "=================== Info about pipeline 'en_core_web_trf' ===================\u001b[0m\n",
            "\n",
            "lang                en                            \n",
            "name                core_web_trf                  \n",
            "version             3.8.0                         \n",
            "description         English transformer pipeline (Transformer(name='roberta-base', piece_encoder='byte-bpe', stride=104, type='roberta', width=768, window=144, vocab_size=50265)). Components: transformer, tagger, parser, ner, attribute_ruler, lemmatizer.\n",
            "author              Explosion                     \n",
            "email               contact@explosion.ai          \n",
            "url                 https://explosion.ai          \n",
            "license             MIT                           \n",
            "spacy_version       >=3.8.0,<3.9.0                \n",
            "spacy_git_version   5010fcbd3                     \n",
            "vectors             {'width': 0, 'vectors': 0, 'keys': 0, 'name': None}\n",
            "pipeline            ['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
            "components          ['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
            "disabled            []                            \n",
            "sources             [{'name': 'OntoNotes 5', 'url': 'https://catalog.ldc.upenn.edu/LDC2013T19', 'license': 'commercial (licensed by Explosion)', 'author': 'Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, Ann Houston'}, {'name': 'ClearNLP Constituent-to-Dependency Conversion', 'url': 'https://github.com/clir/clearnlp-guidelines/blob/master/md/components/dependency_conversion.md', 'license': 'Citation provided for reference, no code packaged with model', 'author': 'Emory University'}, {'name': 'WordNet 3.0', 'url': 'https://wordnet.princeton.edu/', 'author': 'Princeton University', 'license': 'WordNet 3.0 License'}, {'name': 'roberta-base', 'author': 'Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov', 'url': 'https://github.com/pytorch/fairseq/tree/master/examples/roberta', 'license': ''}]\n",
            "requirements        ['spacy-curated-transformers>=0.2.2,<1.0.0']\n",
            "source              /usr/local/lib/python3.12/dist-packages/en_core_web_trf\n",
            "download_url        https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy info en_core_web_trf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTxeCyRP9Ds5",
        "outputId": "12d5c3c7-d7cb-44ae-cdf0-200ea7794c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r⠙ Loading compatibility table...\r⠹ Loading compatibility table...\r\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================ Installed pipeline packages (spaCy v3.8.11) ================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.12/dist-packages/spacy\u001b[0m\n",
            "\n",
            "NAME              SPACY            VERSION                            \n",
            "en_core_web_trf   >=3.8.0,<3.9.0   \u001b[38;5;2m3.8.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "en_core_web_sm    >=3.8.0,<3.9.0   \u001b[38;5;2m3.8.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd_Tu0YX9D1C",
        "outputId": "5f5c9e52-2744-445c-ed49-5c76737ec7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spacy version installed: 3.8.11\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "print (f\"Spacy version installed: {spacy.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOtMkQrY-N61"
      },
      "source": [
        "**c. Verificar si se puede usar GPU**\n",
        "\n",
        "Si estamos con una GPU, el parámetro gpu-id será 0. Con este cambio, spaCy utilizará la GPU y se acelerará mucho el tiempo de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uC_sXSz-Ooq",
        "outputId": "5bb90093-a21f-4c36-b93c-1399fd116c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_id = 0    # Use the first available GPU\n",
        "    print(f\"Using GPU {gpu_id}\")\n",
        "else:\n",
        "    gpu_id = -1   # Use CPU\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L35Q-Df_5yfC"
      },
      "source": [
        "**d. Entrenar el modelo `en_core_web_trf` usando la función train de spaCy.**\n",
        "\n",
        "\n",
        "SpaCy realiza el entrenamiento del modelo de acuerdo con los parámetros del fichero de configuración 'config.cfg'. Una descripción de las secciones de esta configuración la puedes encontrar en: https://spacy.io/usage/training#config; describe algún cambio que realizarías si crees que puede mejorar el entrenamiento.\n",
        "\n",
        "Además, considera que en el fichero 'config.cfg' no se determina un número prefijado de *epochs* (ver sección [training] del fichero). El criterio para finalizar viene determinado por los parámetros *max_steps* (20000) y *patience* (1600). Es decir el entrenamiento finalizaría si se cumple una de las condiciones:\n",
        "* al cabo de 20000 'batches' procesados\n",
        "* o bien tras 1600 'batches' procesados, no ha habido mejora en el modelo.\n",
        "\n",
        "Por restricciones de tiempo (o por no consumir las *compute unit* disponibles en Google Colab), si se observa que tras varias iteraciones (por ejemplo a partir de la tercera iteración) el modelo ha ido mejorando (columna SCORE) y tiene un valor superior a 0.9, interrumpir manualmente el proceso. El 'best model' hasta esa iteración se encontrará en el path '{my_path_pra2}/NER/output_ner/model-best'. Este modelo es el que se podrá utilizar para validar o predecir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLQ77Tv0ss5J",
        "outputId": "98b6ff85-cddc-4b29-95a7-6acf96e5279b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "[OK] Modelo 'en_core_web_lg' instalado. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "print(\"\\n[OK] Modelo 'en_core_web_lg' instalado. \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pcV6C0sr2yZ",
        "outputId": "524fd905-280b-4d43-de87-598085df3493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[38;5;1m✘ The provided output file already exists. To force overwriting the\n",
            "config file, set the --force or -F flag.\u001b[0m\n",
            "\n",
            " Archivo config.cfg generado con éxito en /NER/\n"
          ]
        }
      ],
      "source": [
        "# archivo de configuración base para NER con Transformers (GPU)\n",
        "!python -m spacy init config /content/drive/MyDrive/NER/config.cfg --lang en --pipeline ner --optimize accuracy --gpu\n",
        "print(\" Archivo config.cfg generado con éxito en /NER/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k80EbjlqcA_",
        "outputId": "154871c2-6245-419b-9cf3-3a8854a56476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Iniciando el entrenamiento del modelo Transformer...\n",
            "\n",
            "\u001b[38;5;4mℹ Saving to output directory: /content/drive/MyDrive/NER/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    128.50    0.49    0.82    0.35    0.00\n",
            "  0     200        830.00   9397.02   66.15   67.44   64.91    0.66\n",
            "  0     400       1582.68   6002.51   74.60   75.57   73.66    0.75\n",
            "  0     600        109.43   2692.11   76.96   77.93   76.02    0.77\n",
            "  0     800         75.62   1888.92   83.83   85.21   82.50    0.84\n",
            "  1    1000        104.24   1848.67   85.50   86.71   84.33    0.86\n",
            "  1    1200        118.58   1294.51   83.35   83.05   83.64    0.83\n",
            "  1    1400        127.98   1469.36   86.05   85.83   86.27    0.86\n",
            "  1    1600        279.07   1667.71   85.89   87.53   84.32    0.86\n",
            "  2    1800        148.82   1469.87   87.64   87.49   87.80    0.88\n",
            "  2    2000        172.75   1091.71   87.46   88.02   86.91    0.87\n",
            "  2    2200        291.67   1465.29   88.02   88.36   87.68    0.88\n",
            "  3    2400        271.04   1385.08   89.26   89.80   88.72    0.89\n",
            "  3    2600        309.77   1298.22   89.83   90.25   89.41    0.90\n",
            "  4    2800        285.98   1191.90   89.65   89.98   89.31    0.90\n",
            "  4    3000        455.57   1520.97   90.03   89.93   90.14    0.90\n",
            "  5    3200        576.19   1397.69   90.03   90.49   89.57    0.90\n",
            "  6    3400       2400.15   1286.32   89.91   90.00   89.82    0.90\n",
            "  7    3600        427.48    917.76   90.46   90.43   90.49    0.90\n",
            "  8    3800        469.36    911.70   90.38   90.05   90.73    0.90\n",
            "  9    4000        447.63    880.80   91.24   91.05   91.43    0.91\n",
            "  9    4200        519.68    701.99   90.02   90.06   89.97    0.90\n",
            " 10    4400        375.67    564.29   90.89   90.88   90.90    0.91\n",
            " 11    4600        658.21    640.14   90.70   91.09   90.32    0.91\n",
            " 12    4800        694.11    656.83   90.59   90.65   90.53    0.91\n",
            " 13    5000        731.83    600.31   90.92   91.51   90.34    0.91\n",
            " 13    5200        490.01    433.87   90.76   90.69   90.83    0.91\n",
            " 14    5400        602.53    442.90   90.09   90.35   89.84    0.90\n",
            " 15    5600        774.08    490.73   90.45   90.57   90.34    0.90\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/NER/output/model-last\n",
            "\n",
            "[FIN] Entrenamiento completado. El modelo se encuentra en: /content/drive/MyDrive/NER/output/model-best\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "path_config = \"/content/drive/MyDrive/NER/config.cfg\"\n",
        "path_train  = \"/content/drive/MyDrive/NER/train.spacy\"\n",
        "path_valid  = \"/content/drive/MyDrive/NER/valid.spacy\"\n",
        "path_output = \"/content/drive/MyDrive/NER/output\"\n",
        "\n",
        "#  active_gpu sea un número (0 para GPU, -1 para CPU)\n",
        "\n",
        "try:\n",
        "    print(f\"Usando GPU ID: {active_gpu}\")\n",
        "except NameError:\n",
        "    active_gpu = 0\n",
        "\n",
        "print(\" Iniciando el entrenamiento del modelo Transformer...\\n\")\n",
        "\n",
        "!python -m spacy train $path_config \\\n",
        "    --output $path_output \\\n",
        "    --paths.train $path_train \\\n",
        "    --paths.dev $path_valid \\\n",
        "    --gpu-id $active_gpu\n",
        "\n",
        "print(f\"\\n[FIN] Entrenamiento completado. El modelo se encuentra en: {path_output}/model-best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOlpHvLn6Qfg"
      },
      "source": [
        "**e. Predicción de un texto de ejemplo (inferencia con el modelo entrenado).**\n",
        "\n",
        "Cargar el mejor modelo entrenado y utilizarlo para predecir una frase de ejemplo. Recordar que, si el modelo está ya entrenado y guardado en directorio local es mejor, al iniciar una nueva sesión, recuperar la mejor versión entrenada desde local.\n",
        "\n",
        "**Resultado esperado:** visualizar los resultados de la predicción de la variable `text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yCsl-vA_0UyZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmr1vYmY_MUC"
      },
      "outputs": [],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "text = \"\"\"\\\n",
        "Next Tuesday, Ana plans to travel to London to start her new job at Google. \\\n",
        "Apple announced earnings of $5 billion from iPhone sales in Cupertino.\\\n",
        "Jules Verne visited the Eiffel Tower while he was in Paris.\\\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9epVmjR70lCg",
        "outputId": "c8063abe-2dcc-4947-eab9-c26fa2cfd27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando el mejor modelo desde: /content/drive/MyDrive/NER/output/model-best...\n",
            " Modelo cargado con éxito. Listo para inferencia.\n",
            "\n",
            "The text:\n",
            "\n",
            "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
            "0    Next Tuesday, Ana plans to travel to London to start her new job at Google. Apple announced earnings\n",
            "1     of $5 billion from iPhone sales in Cupertino.Jules Verne visited the Eiffel Tower while he was in P\n",
            "2    aris.\n",
            "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
            "\n",
            "was converted in a spaCy object: <class 'spacy.tokens.doc.Doc'>\n",
            "\n",
            "Token-based analysis. Each token is a spaCy object: <class 'spacy.tokens.token.Token'>\n",
            "\n",
            "Token       Lemma   Syntactic parent   #Tok   Chr_Start   Chr_End   POS   TAG   TAG meaning:   ENT   DEP   DEP meaning:  \n",
            "=====       =====   ================   ====   =========   =======   ===   ===   ============   ===   ===   ============  \n",
            "Next                Next                  0           0         3               None                       None          \n",
            "Tuesday             Tuesday               1           5        11               None                       None          \n",
            ",                   ,                     2          12        12               None                       None          \n",
            "Ana                 Ana                   3          14        16               None           PER         None          \n",
            "plans               plans                 4          18        22               None                       None          \n",
            "to                  to                    5          24        25               None                       None          \n",
            "travel              travel                6          27        32               None                       None          \n",
            "to                  to                    7          34        35               None                       None          \n",
            "London              London                8          37        42               None           LOC         None          \n",
            "to                  to                    9          44        45               None                       None          \n",
            "start               start                10          47        51               None                       None          \n",
            "her                 her                  11          53        55               None                       None          \n",
            "new                 new                  12          57        59               None                       None          \n",
            "job                 job                  13          61        63               None                       None          \n",
            "at                  at                   14          65        66               None                       None          \n",
            "Google              Google               15          68        73               None           LOC         None          \n",
            ".                   .                    16          74        74               None                       None          \n",
            "Apple               Apple                17          76        80               None           ORG         None          \n",
            "announced           announced            18          82        90               None                       None          \n",
            "earnings            earnings             19          92        99               None                       None          \n",
            "of                  of                   20         101       102               None                       None          \n",
            "$                   $                    21         104       104               None                       None          \n",
            "5                   5                    22         105       105               None                       None          \n",
            "billion             billion              23         107       113               None                       None          \n",
            "from                from                 24         115       118               None                       None          \n",
            "iPhone              iPhone               25         120       125               None                       None          \n",
            "sales               sales                26         127       131               None                       None          \n",
            "in                  in                   27         133       134               None                       None          \n",
            "Cupertino           Cupertino            28         136       144               None           LOC         None          \n",
            ".                   .                    29         145       145               None                       None          \n",
            "Jules               Jules                30         146       150               None           PER         None          \n",
            "Verne               Verne                31         152       156               None           PER         None          \n",
            "visited             visited              32         158       164               None                       None          \n",
            "the                 the                  33         166       168               None                       None          \n",
            "Eiffel              Eiffel               34         170       175               None           LOC         None          \n",
            "Tower               Tower                35         177       181               None           LOC         None          \n",
            "while               while                36         183       187               None                       None          \n",
            "he                  he                   37         189       190               None                       None          \n",
            "was                 was                  38         192       194               None                       None          \n",
            "in                  in                   39         196       197               None                       None          \n",
            "Paris               Paris                40         199       203               None           LOC         None          \n",
            ".                   .                    41         204       204               None                       None          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/spacy/glossary.py:20: UserWarning: [W118] Term '' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
            "  warnings.warn(Warnings.W118.format(term=term))\n"
          ]
        }
      ],
      "source": [
        "# ruta del mejor modelo guardado en Drive\n",
        "path_best_model = \"/content/drive/MyDrive/NER/output/model-best\"\n",
        "\n",
        "print(f\"Cargando el mejor modelo desde: {path_best_model}...\")\n",
        "\n",
        "try:\n",
        "    # cargar modelo\n",
        "    # spacy.load para recuperar la arquitectura Transformer y sus pesos\n",
        "    nlp_trained = spacy.load(path_best_model)\n",
        "    print(\" Modelo cargado con éxito. Listo para inferencia.\\n\")\n",
        "\n",
        "    # texto de ejemplo (variable 'text')\n",
        "\n",
        "    #  Visualización de resultados con TU función personalizada\n",
        "    # Esta función usará el modelo nlp_trained para analizar la variable 'text'\n",
        "    get_tokens_to_print(nlp_trained, text)\n",
        "\n",
        "except OSError:\n",
        "    print(f\" ERROR: No se pudo encontrar el modelo en {path_best_model}.\")\n",
        "    print(\"Asegurar de que la ruta sea correcta y el entrenamiento haya finalizado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TR08_0r7dIT"
      },
      "source": [
        "**f. Evaluar los resultados obtenidos y calcular las métricas.**\n",
        "\n",
        "**Salida Esperada**: Cálculo de las métricas utilizando los datos de prueba.\n",
        "\n",
        "**Importante:** Antes del cálculo de las métricas, no olvidar convertir el formato del archivo test.txt al formato que entiende spaCy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T513UTi-DAuQ",
        "outputId": "ecd54f0d-597f-43cd-9f8f-9ef4084f7165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU 0\n"
          ]
        }
      ],
      "source": [
        "#Usar GPU de ser posible:\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_id = 0\n",
        "    print(f\"Using GPU {gpu_id}\")\n",
        "else:\n",
        "    gpu_id = -1   # Us CPU\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJqZUm9k7gNb",
        "outputId": "e7b5141c-7edd-488c-de1c-c528647d801f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Convirtiendo archivo de test: test.txt \n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3684 documents):\n",
            "/content/drive/MyDrive/NER/test.spacy\u001b[0m\n",
            " [OK] Archivo 'test.spacy' generado correctamente.\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "def prepare_test_data(path_ner):\n",
        "    \"\"\"Convierte el archivo test.txt al formato binario .spacy.\n",
        "\n",
        "    Parameters:\n",
        "      path_ner (str): Ruta de la carpeta NER en Drive.\n",
        "    \"\"\"\n",
        "    input_test = os.path.join(path_ner, \"test.txt\")\n",
        "\n",
        "    if os.path.exists(input_test):\n",
        "        print(f\" Convirtiendo archivo de test: test.txt \")\n",
        "        #  conversor de spaCy\n",
        "        !python -m spacy convert {input_test} {path_ner} --converter ner\n",
        "        print(f\" [OK] Archivo 'test.spacy' generado correctamente.\")\n",
        "    else:\n",
        "        print(f\" [ERROR] No se encontró 'test.txt' en {path_ner}. Verifica la descarga.\")\n",
        "\n",
        "# Ejecutar la conversión\n",
        "prepare_test_data(\"/content/drive/MyDrive/NER\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEPfguew1ZPt",
        "outputId": "0667be6c-70dc-4acb-cdaa-2ccca7c36351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Calculando métricas en el conjunto de prueba (TEST)...\n",
            "\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     -    \n",
            "NER P   85.05\n",
            "NER R   85.80\n",
            "NER F   85.42\n",
            "SPEED   15216\n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "LOC    88.75   90.83   89.78\n",
            "PER    87.82   91.40   89.58\n",
            "MISC   79.80   78.77   79.28\n",
            "ORG    80.50   78.27   79.37\n",
            "\n",
            "\n",
            "[FIN] Evaluación finalizada.\n"
          ]
        }
      ],
      "source": [
        "#  rutas necesarias\n",
        "path_model_best = \"/content/drive/MyDrive/NER/output/model-best\"\n",
        "path_test_spacy = \"/content/drive/MyDrive/NER/test.spacy\"\n",
        "\n",
        "#  ID de la GPU para acelerar la evaluación si está disponible\n",
        "try:\n",
        "    gpu_to_use = active_gpu\n",
        "except NameError:\n",
        "    gpu_to_use = 0\n",
        "\n",
        "print(\" Calculando métricas en el conjunto de prueba (TEST)...\\n\")\n",
        "\n",
        "#  evaluación oficial de spaCy\n",
        "!python -m spacy evaluate $path_model_best $path_test_spacy --gpu-id $gpu_to_use\n",
        "\n",
        "print(\"\\n[FIN] Evaluación finalizada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPUPNSqbXT-T"
      },
      "source": [
        "## 2.2 NEL (1 punto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itchQVx3XcU6"
      },
      "source": [
        "En esta sección, la idea es obtener los enlaces en Wikidata relacionados con las entidades que se obtienen usando spaCy.\n",
        "Por tanto, desarrolla una función que, dado un texto, obtenga automáticamente las entidades relacionadas con Wikidata.\n",
        "Para implementar la solución, podéis usar, por ejemplo, la librería `wikidata.client`, o realizar solicitudes directas a la API, usando la librería `requests`.\n",
        "\n",
        "**Importante:** En el Notebook de Ejemplo, se proporciona un texto en catalán, por ello se carga el modelo `ca_core_news_sm`. Para analizar frases en español, cambiar el modelo, por ejemplo, usar `es_core_news_sm`. Además, si se usa `requests`, colocar el lenguaje en la URL de acceso al EndPoint de WikiData.\n",
        "\n",
        "**Salida Esperada**: Lista de las entidades reconocidas en el texto, con su respectiva URI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bp_251gCFn-",
        "outputId": "ca2fe1be-6d52-4ae9-e7c5-90e0ed870ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikidata\n",
            "  Downloading wikidata-0.9.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Downloading wikidata-0.9.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wikidata\n",
            "Successfully installed wikidata-0.9.0\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "nel_model = \"es_core_news_sm\" # Modelo a usar, se puede cambiar a \"ca_core_news_sm\" para procesar frases en catalán.\n",
        "\n",
        "!pip install wikidata\n",
        "!python -m spacy download '{nel_model}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKZ_bvCVXjI2"
      },
      "outputs": [],
      "source": [
        "#############################################\n",
        "# SOLUCIÓN                                  #\n",
        "#############################################\n",
        "\n",
        "text = \"\"\"\\\n",
        "El escritor y guionista hungarés László Krasznahorkai \\\n",
        "ha ganado el Premio Nobel de Literatura 2025.\n",
        "El reciente Nobel, de 71 años, tiene su primera novela \"Tango Satànic\" (1985) \\\n",
        "traducida al catalán por Carles Dachs, editada en Barcelona este 2025 por \\\n",
        "Edicions del Cràter, con sede en Barcelona.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "# cargar modelo en español\n",
        "if not spacy.util.is_package(\"es_core_news_sm\"):\n",
        "    !python -m spacy download es_core_news_sm\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "def get_wikidata_id_robust(entity_text):\n",
        "    \"\"\"\n",
        "    Busca una entidad en Wikidata y devuelve su ID y descripción.\n",
        "    Incluye User-Agent para evitar bloqueo 403.\n",
        "    \"\"\"\n",
        "    url = \"https://www.wikidata.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"wbsearchentities\",\n",
        "        \"language\": \"es\",\n",
        "        \"format\": \"json\",\n",
        "        \"search\": entity_text,\n",
        "        \"limit\": 1\n",
        "    }\n",
        "    # identificarse\n",
        "    headers = {\n",
        "        'User-Agent': 'EstudiantePRA2/1.0 (tu_email@uoc.edu)'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params, headers=headers, timeout=5)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if data.get(\"search\"):\n",
        "                result = data[\"search\"][0]\n",
        "                return result[\"id\"], result.get(\"description\", \"Sin descripción\")\n",
        "            else:\n",
        "                return \"No hallado\", \"Sin resultados\"\n",
        "        else:\n",
        "            return f\"Error {response.status_code}\", \"Bloqueo API\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"Error\", str(e)\n",
        "\n",
        "# procesamineto\n",
        "text_nobel = \"\"\"El escritor y guionista hungarés László Krasznahorkai\n",
        "ha ganado el Premio Nobel de Literatura 2025.\n",
        "El reciente Nobel, de 71 años, tiene su primera novela \"Tango Satànic\" (1985)\n",
        "traducida al catalán por Carles Dachs, editada en Barcelona este 2025 por\n",
        "Edicions del Cràter, con sede en Barcelona.\"\"\"\n",
        "\n",
        "doc_es = nlp_es(text_nobel)\n",
        "\n",
        "print(f\"{'ENTIDAD':<25} | {'TIPO':<10} | {'WIKIDATA ID':<15} | {'DESCRIPCIÓN'}\")\n",
        "print(\"-\" * 120)\n",
        "\n",
        "seen_entities = set()\n",
        "\n",
        "for ent in doc_es.ents:\n",
        "    if ent.text not in seen_entities:\n",
        "        qid, description = get_wikidata_id_robust(ent.text)\n",
        "        # cortamos la descripción para que quepa en la tabla\n",
        "        desc_short = (description[:45] + '..') if len(description) > 45 else description\n",
        "        print(f\"{ent.text:<25} | {ent.label_:<10} | {str(qid):<15} | {desc_short}\")\n",
        "        seen_entities.add(ent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1P7U6LUUIaJ",
        "outputId": "08f77ff2-d550-4501-c0f9-ff4504a7ca61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTIDAD                   | TIPO       | WIKIDATA ID     | DESCRIPCIÓN\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "László Krasznahorkai      | PER        | Q512062         | Hungarian novelist and screenwriter\n",
            "Premio Nobel de Literatura 2025 | MISC       | No hallado      | Sin resultados\n",
            "Nobel                     | MISC       | Q36341833       | family name\n",
            "Tango Satànic             | MISC       | Q1315145        | novel by László Krasznahorkai\n",
            "Carles Dachs              | PER        | Q56400459       | Sin descripción\n",
            "Barcelona                 | LOC        | Q1492           | city in Catalonia, Spain\n",
            "Edicions del Cràter       | ORG        | Q115940215      | Sin descripción\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}